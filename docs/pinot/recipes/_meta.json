{
    "csv-files-spaces-column-names": "Importing CSV files with columns containing spaces",
    "debezium-cdc": "Ingest CDC data using PostgreSQL, Kafka, and Debezium",
    "dynamodb-pinot-cdc": "Ingesting DynamoDB data into Pinot using Kinesis and DynamoDB decoder",
    "import-data-files-different-directories": "Import data files from different directories",
    "ingest-csv-files-from-s3": "Ingest CSV files from a S3 bucket",
    "ingest-json-files-kafka": "Ingesting JSON files from Kafka",
    "ingest-json-files": "Ingesting JSON files",
    "ingest-parquet-files-from-s3-using-spark": "Ingest Parquet Files from S3 Using Spark",
    "kafka-sasl": "Connecting to Kafka with SASL authentication",
    "kafka-ssl-sasl": "Connecting to Kafka with SSL and SASL authentication",
    "github-events-stream-kinesis": "Ingest Github API Events using Kinesis",
    "groovy-transformation-functions": "Groovy Transformation Functions",
    "json-transformation-functions": "JSON Transformation Functions",
    "chaining-transformation-functions": "Chaining Transformation Functions",
    "upserts-full": "Full Upserts in Pinot",
    "upserts-partial": "Partial Upserts in Pinot",
    "real-time-offline-job": "Manually schedule real-time to offline job",
    "real-time-offline-job-automatic-scheduling": "Automatically schedule real-time to offline job",
    "datetime-string-to-timestamp": "Converting DateTime strings to Timestamps",
    "lookup-joins": "Lookup-based Join Support",
    "merge-segments-realtime": "Merge real-time segments",
    "merge-small-segments": "Merge small segments",
    "infer-schema-avro": "Infer Pinot schema from Avro schema",
    "infer-schema-json-data": "Infer Pinot schema from JSON data",
    "backfill": "Backfill offline segment",
    "upserts-real-time-offline-job": "Upserts and the real-time to offline job",
    "configuring-segment-threshold": "Configuring the segment threshold",
    "time-boundary-hybrid-table": "Get time boundary",
    "filtering-ingestion": "Filtering records during ingestion",
    "pulsar": "Ingest from Apache Pulsar",
    "json-unnest": "Unnest arrays in JSON documents",
    "json-unnest-rename-fields": "Rename fields in unnested or flattened JSON documents",
    "json-flatten": "Flatten objects in JSON documents",
    "extract-parts-of-date": "Extract parts of date",
    "handle-null-values": "Handle null values",
    "combine-fields": "Combine fields during import",
    "minio-deep-store": "MinIO as Deep Store",
    "geospatial-default-value": "Default value for Geospatial columns",
    "geospatial-indexing": "Indexing Geospatial points",
    "geospatial": "Storing Geospatial objects",
    "google-cloud-storage-deep-store": "Google Cloud Storage as Deep Store",
    "fixed-hostname": "Fixed host names",
    "force-commit": "Force Commit",
    "ingest-avro": "Ingesting Avro messages",
    "json-index": "Indexing JSON columns",
    "json-update-index": "Updating JSON index",
    "pause-resume-consumption": "Pause and Resume Consumption",
    "query-by-segment": "Query table by segment",
    "removing-server": "Removing a server",
    "segment-assignment": "Checking segment assignment",
    "startree-index": "Using a star-tree index",
    "managed-offline-flow": "Managed offline flow",
    "genai": "Real-Time RAG Pinot"
}
